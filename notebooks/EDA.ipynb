


!pip install ultralytics deep_sort_realtime

import cv2
import os
import json


from deep_sort_realtime.deepsort_tracker import DeepSort
from ultralytics import YOLO


person_detector = YOLO("yolov8n.pt")
box_detector=YOLO("yolov8n.pt")



def init_video_io(video_path, output_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise IOError(f"[ERROR] Cannot open video: {video_path}")

    fps   = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height= int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"[INFO] Video: {video_path}\n - FPS: {fps}\n - Size: {width}Ã—{height}\n - Frames: {total}")

    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    if not writer.isOpened():
        raise IOError(f"[ERROR] Cannot open writer at {output_path}")
    return cap, writer, fps


def run_tracking(detector_person, detector_box, tracker, cap, writer,
                 save_metadata=False, metadata_path=None,
                 debug=False, log_interval=500,
                 threshold=0.6, box_threshold=0.5,
                 run_name="default"):
    
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_idx = 0
    log_file = open(metadata_path, 'w') if save_metadata and metadata_path else None

    while True:
        ret, frame = cap.read()
        if not ret:
            if debug:
                print(f"[{run_name}] Reached end of stream at frame {frame_idx}")
            break

        # ========== Detection ==========
        res_p = detector_person(frame, verbose=False)[0]
        res_b = detector_box(frame, verbose=False)[0]

        detections = []
        # Person Detection
        for box in res_p.boxes.data.tolist():
            x1, y1, x2, y2, score, cls = box
            label = res_p.names[int(cls)].lower()
            if label == "person" and score > threshold:
                detections.append(([x1, y1, x2 - x1, y2 - y1], score, "person"))

        # Box/Object Detection
        for box in res_b.boxes.data.tolist():
            x1, y1, x2, y2, score, cls = box
            label = res_b.names[int(cls)].lower()
            valid_labels = ["cell phone", "book", "remote", "laptop", "keyboard", "mouse", "bottle", "suitcase"]
            if label in valid_labels and score > box_threshold:
                detections.append(([x1, y1, x2 - x1, y2 - y1], score, "box"))

        # ========== Tracking ==========
        tracks = tracker.update_tracks(detections, frame=frame)

        # ========== Annotation ==========
        for tr in tracks:
            if not tr.is_confirmed(): continue
            tid = tr.track_id
            l, t, r, b = tr.to_ltrb()
            cv2.rectangle(frame, (int(l), int(t)), (int(r), int(b)), (0, 255, 0), 2)
            cv2.putText(frame, f'ID{tid}', (int(l), int(t) - 6),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 1)

            if log_file:
                log_file.write(json.dumps({
                    'frame': frame_idx,
                    'track_id': tid,
                    'bbox': {'x1': int(l), 'y1': int(t), 'x2': int(r), 'y2': int(b)},
                    'label': tr.get_det_class() or 'unknown'
                }) + '\n')

        writer.write(frame)
        frame_idx += 1

        if debug and frame_idx % log_interval == 0:
            print(f"[{run_name}] Wrote frame {frame_idx}")

    cap.release()
    writer.release()

    if frame_idx < total_frames:
        print(f"[{run_name}] [ERROR] Processed only {frame_idx}/{total_frames} frames!")
    else:
        print(f"[{run_name}] [SUCCESS] Processed all {total_frames} frames.")

    if log_file: log_file.close()
    if debug:
        print(f"[{run_name}] Finished writing {frame_idx} frames")
